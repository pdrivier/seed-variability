---
title: "Variation in surprisal across seeds and scales"
author: "Pam Rivi√®re and Sean Trott"
date: "March 17, 2025"
output:
  html_document:
    keep_md: yes
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(dpi = 300, fig.format = "pdf")
```


```{r include=FALSE}
library(tidyverse)
library(lme4)
library(viridis)
library(ggridges)
library(lmerTest)
library(ggrepel)
library(ggcorrplot)

all_colors <- viridis::viridis(10, option = "mako")
my_colors <- all_colors[c(3, 5, 7)]  # Selecting specific colors from the palette
```

# Load Pythia data


Here, we analyze data looking at the average attention each head gives from each token to the previous token.

```{r include=FALSE}
# setwd("/Users/seantrott/Dropbox/UCSD/Research/NLMs/epistemology/seed-variability/src/analysis")
directory_path <- "../../data/processed/surprisals/"
csv_files <- list.files(path = directory_path, pattern = "*.csv", full.names = TRUE)
csv_list <- csv_files %>%
  map(~ read_csv(.))
df_pythia_models <- bind_rows(csv_list)
nrow(df_pythia_models)

table(df_pythia_models$seed)
table(df_pythia_models$dataset_name)
max(df_pythia_models$step)

```


# Surprisal over time by seed

**TODO**:

- Mean/SD surprisal over time, by seed, by architecture. 
- Scaling law in `surprisal ~ #params` over different checkpoints. 
- Do larger models have more or less variance across seeds in surprisal? 
- Are larger models more or less *correlated* at a word-by-word level? 
- Are larger models correlated across seeds more *quickly* throughout pretraining? What about with smaller models, i.e., are larger models already capturing the wisdom of the crowd of smaller models?
(For this, compare the *average* of 14m at a given timepoint with each individual 14m seed, as well as with 70m at that timepoint.)
- How does within-model (across-seed) correlation compare to across-models? When does a model "look like itself"? (MDS, etc.)
- Compare each model to a set of baseline models at each timepoint (e.g., GPT-2), to get a sense for the similarity to another model family.
- How do these trajectories compare to the trajectories of weight changes?
- Also do with Pythia cosine distances for RAW-C?


```{r}
### Avg. by step
df_surprisal_by_seed = df_pythia_models %>% 
  group_by(n_params, model, seed_name, revision, step, seed) %>%
  summarise(mean_surprisal = mean(surprisal),
            sd_surprisal = sd(surprisal)) %>%
  mutate(step_modded = step + 1)

### Avg. across seeds
df_surprisal_avg = df_surprisal_by_seed %>% 
  group_by(n_params,model, revision, step) %>%
  summarise(mean_surprisal_across_seeds = mean(mean_surprisal),
            surprisal_var_across_seeds = sd(mean_surprisal),
            surprisal_mean_range = max(mean_surprisal) - min(mean_surprisal),
            se_surprisal = sd(mean_surprisal) /sqrt(n()))  %>%
  mutate(step_modded = step + 1)


ggplot() +
  geom_point(data = df_surprisal_by_seed,
             aes(x = step_modded,
                 y = mean_surprisal,
                 color = reorder(model, n_params)),
             size = 2, alpha = 0.3) +
  geom_line(data = df_surprisal_avg,
            aes(x = step_modded,
                y = mean_surprisal_across_seeds,
                color = reorder(model, n_params)),
            size = 1.3) +
  geom_point(data = df_surprisal_avg,
             aes(x = step_modded,
                 y = mean_surprisal_across_seeds,
                 color = reorder(model, n_params)),
             size = 4, alpha = 0.4) +
  theme_minimal() +
  labs(x = "Training Step (Log10)",
       y = "Mean Surprisal across seeds",
       color = "") +
  scale_x_log10() +
  geom_vline(xintercept = 1000,
             linetype = "dotted",
             size = 1.2) +
  theme(text = element_text(size = 15),
        legend.position = "bottom") +
  scale_color_manual(values = viridisLite::viridis(4, option = "mako", 
                                                    begin = 0.8, end = 0.15))




df_surprisal_avg %>%
  ggplot(aes(x = step_modded,
             y = surprisal_var_across_seeds,
             color = reorder(model, n_params))) +
  geom_line(size = 1.3) +
  geom_point(size = 4, alpha = .4) +
  theme_minimal() +
  labs(x = "Training Step (Log10)",
       y = "SD Surprisal across seeds",
       color = "") +
  scale_x_log10() +
  geom_vline(xintercept = 1000, 
             linetype = "dotted", 
             size = 1.2) +
  theme(text = element_text(size = 15),
        legend.position = "bottom") +
  scale_color_manual(values = viridisLite::viridis(4, option = "mako", 
                                                begin = 0.8, end = 0.15))



df_surprisal_avg %>%
  ggplot(aes(x = step_modded,
             y = surprisal_mean_range,
             color = reorder(model, n_params))) +
  geom_line(size = 1.3) +
  geom_point(size = 4, alpha = .4) +
  theme_minimal() +
  labs(x = "Training Step (Log10)",
       y = "Range in mean surprisal across seeds",
       color = "") +
  scale_x_log10() +
  geom_vline(xintercept = 1000, 
             linetype = "dotted", 
             size = 1.2) +
  theme(text = element_text(size = 15),
        legend.position = "bottom") +
  scale_color_manual(values = viridisLite::viridis(4, option = "mako", 
                                                begin = 0.8, end = 0.15))




```


### Scaling over time

```{r}

scaling_law_df <- df_surprisal_by_seed %>%
  group_by(step_modded) %>%
  nest() %>%
  mutate(
    model_fit = map(data, ~ lm(mean_surprisal ~ log10(n_params), data = .x)),
    coef_info = map(model_fit, ~ tidy(.x))
  ) %>%
  unnest(coef_info) %>%
  filter(term == "log10(n_params)") %>%
  select(step_modded, estimate, std.error, statistic, p.value)


scaling_law_df %>%
  ggplot(aes(x = step_modded, y = estimate)) +
  geom_line() +
  geom_point() +
  geom_ribbon(aes(ymin = estimate - std.error, ymax = estimate + std.error), alpha = 0.2) +
  scale_x_log10() +
  labs(
    title = "Scaling Law Coefficient Over Time",
    x = "Training Step (log10)",
    y = "Coefficient for log10(n_params)"
  ) +
  geom_vline(xintercept = 1000, 
             linetype = "dotted", 
             size = 1.2) +
  theme_minimal() +
  theme(text = element_text(size = 15),
        legend.position="bottom")
```


# Across-seed correlations


```{r}

#### By model/seed
df_wide <- df_pythia_models %>%
  mutate(model_id = paste(model, "-", seed_name)) %>%
  select(step, model_id, surprisal, sentence, token) %>%
  group_by(model_id, step, sentence) %>%
  summarise(surprisal = mean(surprisal, na.rm = TRUE), .groups = "drop") %>%
  pivot_wider(
    names_from = model_id,
    values_from = surprisal
  )





### Get ordered model_id by params
model_id_to_params <- df_pythia_models %>%
  select(model, seed_name, n_params) %>%
  distinct() %>%
  mutate(model_id = paste(model, "-", seed_name)) %>%
  distinct(model_id, n_params) %>%
  arrange(n_params) %>%
  pull(model_id)


# Correlation matrix
cor_matrix <- df_wide %>%
  filter(step == 8) %>%
  select(-step, -sentence) %>%
  cor(use = "pairwise.complete.obs")

# Order it according to number of params
cor_matrix_ordered <- cor_matrix[ordered_model_ids, ordered_model_ids]

# Plot
ggcorrplot(cor_matrix_ordered,
           hc.order = FALSE,
           method = "square",
           # type = "lower",
           lab = FALSE) +
  theme(text = element_text(size = 12))



### 
cor_long <- df_wide %>%
  # filter(step <= 1000) %>%
  group_by(step) %>%
  group_map(~ {
    mat <- .x %>%
      select(-sentence) %>%
      cor(use = "pairwise.complete.obs")
    
    # Ensure model IDs in both dimensions are ordered by model size
    mat <- mat[ordered_model_ids, ordered_model_ids]

    # Convert to tidy long format
    as.data.frame(mat) %>%
      rownames_to_column(var = "Var1") %>%
      pivot_longer(
        cols = -Var1,
        names_to = "Var2",
        values_to = "value"
      ) %>%
      mutate(step = .y$step)
  }) %>%
  bind_rows() %>%
  mutate(
    Var1 = factor(Var1, levels = ordered_model_ids),
    Var2 = factor(Var2, levels = ordered_model_ids)
  )


cor_long %>%
  ggplot(aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  coord_fixed() +
  theme_minimal(base_size = 10) +
  scale_fill_gradient2(
    low = "blue",
    mid = "white",
    high = "red",
    midpoint = 0,
    limit = c(-1, 1),
    name = "Corr"
  ) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5),
        axis.title = element_blank()) +
  labs(title = "Step: {closest_state}") +
  transition_states(step, transition_length = 2, state_length = 1) +
  ease_aes("linear")

cor_long %>%
  filter(step == 10000) %>%
  ggplot(aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  coord_fixed() +
  theme_minimal(base_size = 10) +
  scale_fill_gradient2(
    low = "blue",
    mid = "white",
    high = "red",
    midpoint = 0,
    limit = c(-1, 1),
    name = "Corr"
  ) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5),
        axis.title = element_blank()) 


##### Correlation across all
cor_by_group <- df_wide %>%
  group_by(step) %>%
  summarise(
    cor_matrix = list(
      cor(select(cur_data(), starts_with("pythia-")), use = "pairwise.complete.obs")
    ),
    .groups = "drop"
  )


cor_long <- cor_by_group %>%
  mutate(cor_df = map(cor_matrix, ~ as.data.frame(as.table(.)))) %>%
  unnest(cor_df) %>%
  rename(seed1 = Var1, seed2 = Var2, correlation = Freq) %>%
  filter(seed1 != seed2) %>%
  separate(seed1, into = c("model1", "seed_name1"), sep = " - ") %>%
  separate(seed2, into = c("model2", "seed_name2"), sep = " - ") %>%
  mutate(same_model = model1 == model2) %>%
  mutate(step_modded = step + 1)

# Step 2: Compute mean correlation per step (and optionally model)
mean_cor_by_step <- cor_long %>%
  group_by(model1, model2, same_model, step) %>%
  summarise(
    mean_corr = mean(correlation, na.rm = TRUE),
    se_corr = sd(correlation, na.rm = TRUE) / sqrt(n()),
    .groups = "drop"
  ) %>%
  mutate(step_modded = step + 1)

ggplot(mean_cor_by_step, aes(x = step_modded, y = mean_corr, color = model2)) +
  geom_line(size = 1.2) +
  geom_point(size = 2) +
  geom_ribbon(aes(ymin = mean_corr - 2 * se_corr,
                  ymax = mean_corr + 2 * se_corr,
                  fill = model2),
              alpha = 0.5, color = NA) +
  theme_minimal() +
  labs(
    title = "Inter-seed Correlation",
    x = "Training Step (Log10)",
    y = "Mean Correlation",
    color = "",
    fill = ""
  ) +
  geom_vline(xintercept = 1000, 
             linetype = "dotted", 
             size = 1.2) +
  scale_x_log10() +
  theme(text = element_text(size = 15),
        legend.position = "bottom") +
  scale_color_manual(values = viridisLite::viridis(4, option = "mako", 
                                                   begin = 0.8, end = 0.15)) +
  scale_fill_manual(values = viridisLite::viridis(4, option = "mako", 
                                                  begin = 0.8, end = 0.15)) +
  facet_wrap(~model1)


summary(lmer(correlation ~ log10(step_modded) * same_model + 
               (1 | seed_name1) + (1 | seed_name2), data = cor_long))


s = cor_long %>% 
  filter(step <= 1000) %>% 
  group_by(model1, step_modded, same_model) %>% 
  summarise(m_cor = mean(correlation)) %>%
  mutate(model = model1)

df_params = df_pythia_models %>%
  select(model, n_params) %>%
  distinct() 

s = s %>%
  inner_join(df_params)

summary(lmer(m_cor ~ log10(step_modded) * same_model 
             + log10(n_params) +
               (1 | model), data = s))

ggplot(s, aes(x = step_modded, y = m_cor, color = same_model)) +
  geom_line(size = 1.2) +
  geom_point(size = 2) +
  labs(
    title = "Inter-seed Correlation",
    x = "Training Step (Log10)",
    y = "Mean Correlation",
    color = "",
    fill = ""
  ) +
  geom_vline(xintercept = 1000, 
             linetype = "dotted", 
             size = 1.2) +
  scale_x_log10() +
  theme(text = element_text(size = 15),
        legend.position = "bottom") +
  scale_color_manual(values = viridisLite::viridis(2, option = "mako", 
                                                   begin = 0.8, end = 0.15)) +
  scale_fill_manual(values = viridisLite::viridis(2, option = "mako", 
                                                  begin = 0.8, end = 0.15)) +
  facet_wrap(~model)


##### Multi-dimensional scaling
mds_by_step <- df_wide %>%
  # filter(step <= 1000) %>%
  drop_na() %>%
  group_by(step) %>%
  summarise(
    mds_df = list({
      cor_mat <- cor(select(cur_data(), starts_with("pythia-")), use = "pairwise.complete.obs")
      dist_mat <- as.dist(1 - cor_mat)
      mds <- cmdscale(dist_mat, k = 2)
      as_tibble(mds, .name_repair = "unique") %>%
        mutate(model_id = colnames(cor_mat)) 
    }),
    .groups = "drop"
  ) %>%
  unnest(mds_df) %>%
  separate(model_id, into = c("model", "seed"), sep = " - ") %>%
  rename(x = `...1`, y = `...2`) %>%
  inner_join(df_params)

ggplot(mds_by_step, aes(x, y, 
                        color = reorder(model, n_params))) +
  geom_point() +
  facet_wrap(~ step) +
  theme_bw() +
  labs(x = "MDS 1",
       y = "MDS 2",
       color = "") +
  theme(text = element_text(size = 15),
        legend.position = "bottom") +
  scale_color_manual(values = viridisLite::viridis(4, option = "mako", 
                                                   begin = 0.8, end = 0.15)) 



# Create animated plot
p <- ggplot(mds_by_step, aes(x = x, y = y, color = reorder(model, n_params))) +
  geom_point(size = 3, alpha = 0.8) +
  theme_minimal(base_size = 14) +
  labs(title = "MDS of Model Similarities (Step: {closest_state})",
       x = "MDS Dimension 1",
       y = "MDS Dimension 2",
       color = "Model") +
  theme(text = element_text(size = 15),
        legend.position = "bottom") +
  scale_color_manual(values = viridisLite::viridis(4, option = "mako", 
                                                   begin = 0.8, end = 0.15)) +
  transition_states(step, transition_length = 2, state_length = 1) +
  ease_aes('linear')

# Render
anim <- animate(p, renderer = gifski_renderer(), width = 800, height = 600, 
                fps = 10, duration = 10)
anim


```



# Joining with RT


**TOOD**: Steps --> merge wordlist with sentences based on sentence id and word id. then merge sentences with pythia data.

```{r}

## Words
df_words <- read_excel("../../data/raw/geco-EnglishMaterials.xlsx", sheet = "ALL") %>%
  select(WORD_ID, SENTENCE_ID, WORD, PART_OF_SPEECH, WORD_LENGTH)
## Sentences
df_sentences <- read_excel("../../data/raw/geco-EnglishMaterials.xlsx", sheet = "SENTENCE") %>%
  mutate(SENTENCE = str_squish(SENTENCE))

df_both = df_words %>%
  inner_join(df_sentences)
  

df_160m_final = df_pythia_models %>%
  filter(model == "pythia-14m") %>%
  # filter(step %in% c(1, 143000)) %>%
  # filter(step %in% c(1, 143000)) %>%
  # filter(seed == 1) %>%
  select(step, revision, seed, seed_name, word, surprisal_normed, sentence)

df_rt = read_csv("../../data/raw/reading-times/geco-MonolingualReadingData.csv")

df_rt_subset = df_rt %>%
  mutate(word = WORD) %>%
  select(`...1`, PP_NR, TRIAL, word, WORD_GAZE_DURATION, 
         WORD_ID_WITHIN_TRIAL, WORD_ID) %>%
  filter(PP_NR == "pp21") %>%
  filter(WORD_GAZE_DURATION != ".") %>%
  mutate(WORD_GAZE_DURATION = as.numeric(WORD_GAZE_DURATION)) %>%
  mutate(word_position = WORD_ID_WITHIN_TRIAL - 1)


df_rt_with_info = df_both %>%
  inner_join(df_rt_subset) %>%
  mutate(sentence = SENTENCE)


df_merged = df_160m_final %>%
  inner_join(df_rt_with_info, by = c("word", "sentence"))
nrow(df_merged)


results <- df_merged %>%
  group_by(step, seed_name) %>%
  group_modify(~ {
    model <- lm(WORD_GAZE_DURATION ~ surprisal_normed, data = .x)
    tibble(
      r_squared = summary(model)$r.squared
    )
  })

results %>%
  ggplot(aes(x = step + 1,
             y = r_squared,
             color = seed_name)) +
  scale_x_log10() +
  geom_vline(xintercept = 1000, linetype = "dotted") +
  geom_point(size = 2, alpha = .6)
```

